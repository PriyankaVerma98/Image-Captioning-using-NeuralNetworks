{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaVerma98/Neural_networks_TensorFlow/blob/master/video6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipxGuRNdXPfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUZwaSjeZbOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import imutils\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq-O67or6tkv",
        "colab_type": "code",
        "outputId": "e4cf9c3d-b6b4-43af-b605-5458f3514a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=aedaa5afc04b8c5a69e0890d1036496e4ce26c3dc2f25a60505cbf60b1436ab7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T5rAhi16TPi",
        "colab_type": "code",
        "outputId": "c93dc9a8-6025-410c-9935-475b3ea4ea4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.8 GB  I Proc size: 173.7 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfT3lqCB7DAb",
        "colab_type": "text"
      },
      "source": [
        "Connect to Google Drive to load required files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON43dWVCD5GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory = '/content/drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9SSO1yfDfwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5914EhmREM1s",
        "colab_type": "code",
        "outputId": "f8fddd9a-40e9-4f7f-f67a-293cea7f6391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVOhmV_vEjOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzMhR8DEEoCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXrKhgKHYras",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw3yvRTo_e7w",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**Generate New Captions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjwYtUP_d_t",
        "colab_type": "code",
        "outputId": "1fcc029a-854b-43e1-fa10-a7cc92776da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from pickle import dump\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# create list\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\t# wrap description in tokens\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "# covert a dictionary of clean descriptions to a list of descriptions\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# fit a tokenizer given caption descriptions\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# load training dataset (6K)\n",
        "filename = directory + 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions(directory + 'descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open(directory + 'tokenizer1.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxVdK2iCYvkQ",
        "colab_type": "code",
        "outputId": "6bb78ffa-7d66-4e4e-d776-02f77909ace5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.6 GB  I Proc size: 379.9 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRHZUbg2Y1cF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#OPTIMISED function \n",
        "\n",
        "# extract features from each photo in the directory\n",
        "def extract_features(filename, is_file = 1):\n",
        "\t# load the model\n",
        "\tmodel = VGG16()\n",
        "\t# re-structure the model\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\t# load the photo\n",
        "\tif is_file==1:\n",
        "\t\t# image = load_img(filename, target_size=(224, 224))\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\t# convert the image pixels to a numpy array\n",
        "\t\timage = img_to_array(image)\n",
        "\telse:\n",
        "\t\timage = np.resize(filename, (224,224,3))\n",
        "\t# # convert the image pixels to a numpy array\n",
        "\t# image = img_to_array(image)\n",
        "\t# reshape data for the model\n",
        "\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t# prepare the image for the VGG model\n",
        "\timage = preprocess_input(image)\n",
        "\t# get features\n",
        "\tfeature = model.predict(image, verbose=0)\n",
        "\treturn feature\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'startseq'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor i in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qODaRlW8zSl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the tokenizer\n",
        "tokenizer = load(open(directory + 'tokenizer.pkl', 'rb'))\n",
        "# pre-define the max sequence length (from training)\n",
        "max_length = 34\n",
        "# load the model\n",
        "model = load_model(directory + 'model_20.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKZ5yP7Vaotd",
        "colab_type": "code",
        "outputId": "896ae054-79b5-4c3a-8724-0d900b4cb804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 11.9 GB  I Proc size: 1.4 GB\n",
            "GPU RAM Free: 15671MB | Used: 609MB | Util   4% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5WL9lWfCJ6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pathOut = r\"/content/drive/My Drive/Colab Notebooks/\"\n",
        "# count = 0\n",
        "# success = True\n",
        "# total = []\n",
        "\n",
        "# while success:\n",
        "#     success,image = cap.read()\n",
        "#     if count%40 == 0 :\n",
        "#         cv2.imwrite(pathOut + '2cook3-%d.jpg'%count,image)\n",
        "#     count+=2\n",
        "# printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDB_v2gokUqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_capture = cv2.VideoCapture(directory + \"check2.mp4\")\n",
        "# Check success\n",
        "if not video_capture.isOpened():\n",
        "    raise Exception(\"Could not open video device\")\n",
        "# Set properties. Each returns === True on success (i.e. correct resolution)\n",
        "video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 224)\n",
        "video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 224)\n",
        "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQMT1Zg7nNXS",
        "colab_type": "code",
        "outputId": "a5a0df7a-49d4-4444-c44e-cd9fec64c78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(fps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23.976023976023978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5BxtzLmfvn8",
        "colab_type": "code",
        "outputId": "d82e818b-cb1a-46cc-dbf6-e1b3aae1bf98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "total = [ ]\n",
        "for i in range(0 , 250 , 60) :\n",
        "  photo = extract_features(directory + \"2cook3-%d.jpg\"%i)\n",
        "  description = generate_desc(model, tokenizer, photo, max_length)\n",
        "  print(description)\n",
        "  # im = cv2.imread(directory + \"acheck2-%d.jpg\"%i)\n",
        "  # cv2.putText(im, description, (100,500) , cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3, cv2.LINE_AA)\n",
        "  # cv2.imwrite(directory + '1result%d.jpg'%i,im)\n",
        "  total.append(description)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "startseq man in red shirt is standing on the sidewalk endseq\n",
            "startseq man in red shirt is standing in front of building endseq\n",
            "startseq two girls are playing with recently funny endseq\n",
            "startseq man in red shirt is standing in front of building endseq\n",
            "startseq man in red shirt is standing in front of building endseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsMT_uWm5YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # total = [ ]\n",
        "# # for i in { 6450 ,11760 , 13500, 21900, 32040, 40050 , 35520 } :\n",
        "# #   photo = extract_features(directory + \"acheck2-%d.jpg\"%i)\n",
        "# #   description = generate_desc(model, tokenizer, photo, max_length)\n",
        "# #   print(description)\n",
        "# #   im = cv2.imread(directory + \"acheck2-%d.jpg\"%i)\n",
        "# #   cv2.putText(im, description, (100,500) , cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3, cv2.LINE_AA)\n",
        "# #   cv2.imwrite(directory + '1result%d.jpg'%i,im)\n",
        "#   total.append(description)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJWHOFKBm5e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Read picture. ret === True on success\n",
        "# success = True \n",
        "# count= 0 \n",
        "# pathOut = r\"/content/drive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "# while success:\n",
        "#     success,image = video_capture.read()\n",
        "#     if count%3000 == 0 :\n",
        "#         cv2.imwrite(pathOut + 'acheck2-%d.jpg'%count,image)\n",
        "#     count+= 3000\n",
        "#     GPUs = GPU.getGPUs()\n",
        "#     gpu = GPUs[0]\n",
        "#     printm()\n",
        "\n",
        "# Close device\n",
        "# video_capture.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6QClbIAxXXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGL3rdlbqjQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# photo = extract_features(directory + \"example.jpg\")\n",
        "# description = generate_desc(model, tokenizer, photo, max_length)\n",
        "# print(description)\n",
        "# total.append(description)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viqnScBg7fVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# im = cv2.imread(directory + \"1result6450.jpg\")\n",
        "# cv2.putText(im, \"Hello Piii\", (100,500) , cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3, cv2.LINE_AA)\n",
        "# cv2.imwrite(directory + '1.jpg',im)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}